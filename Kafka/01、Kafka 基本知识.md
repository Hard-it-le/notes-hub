# 什么是 Kafka

![0](https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/7D5C011520844FFEBCE41F145247DCB7/122865)

Kafka 是最初由 Linkedin 公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于 zookeeper 协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于 hadoop 的批处理系统、低延迟的实时系统、Storm/Spark 流式处理引擎，web/nginx 日志、访问日志，消息服务等等，用 scala 语言编写，Linkedin 于 2010 年贡献给了 Apache 基金会并成为顶级开源 项目。

Kafka 主要设计目标:

- 以时间复杂度为 O (1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条消息的传输。
- 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 partition 内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- 支持在线水平扩展

# Kafka 使用场景

- 日志收集：一个公司可以用 Kafka 收集各种服务的 log，通过 kafka 以统一接口服务的方式开放给各种 consumer，例如 hadoop、Hbase、Solr 等。
- 消息系统：解耦和生产者和消费者、缓存消息等。
- 用户活动跟踪：Kafka 经常被用来记录 web 用户或者 app 用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到 kafka 的 topic 中，然后订阅者通过订阅这些 topic 来做实时的监控分析，或者装载到 hadoop、数据仓库中做离线分析和挖掘。
- 运营指标：Kafka 也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

# Kafka 优势

- 高吞吐量：单机每秒处理几十上百万的消息量。即使存储了许多 TB 的消息，它也保持稳定的性能。
- 高性能：单节点支持上千个客户端，并保证零停机和零数据丢失。
- 持久化数据存储：将消息持久化到磁盘。通过将数据持久化到硬盘以及 replication 防止数据丢失。
- 分布式系统，易于向外扩展。所有的 Producer、Broker 和 Consumer 都会有多个，均为分布式的。无需停机即可扩展机器。多个 Producer、Consumer 可能是不同的应用。
- 可靠性 - Kafka 是分布式，分区，复制和容错的。
- 客户端状态维护：消息被处理的状态是在 Consumer 端维护，而不是由 server 端维护。当失败时能自动平衡。
- 支持 online 和 offline 的场景。
- 支持多种客户端语言。Kafka 支持 Java、.NET、PHP、Python 等多种语言。

# Kafka 架构图

![](https://note.youdao.com/yws/public/resource/b0357bdb4821ed2e35ecdbdacd65aa06/xmlnote/EA60D4B78E4E4791B30A5B8507EBC132/122860)

# Kafka 基本概念

kafka 是一个分布式的，分区的消息(官方称之为 commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。可以这样来说，Kafka 借鉴了 JMS 规范的思想，但是确并没有完全遵循 JMS 规范。

## Broker

一个独立的 Kafka 服务器称为 broker。broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker 为消费者提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。单个 broker 可以轻松处理数千个分区以及每秒百万级的消息量。一个 Kafka 节点就是一个 broker，一个或者多个 Broker 可以组成一个 Kafka 集群

## Topic

Kafka 根据 topic 对消息进行归类，发布到 Kafka 集群的每条消息都需要指定一个 topic

## Producer

消息生产者，向 Broker 发送消息的客户端

该角色将消息发布到 Kafka 的 topic 中。broker 接收到生产者发送的消息后，broker 将该消息追加到当前用于追加数据的 segment 文件中。

一般情况下，一个消息会被发布到一个特定的主题上。

- 默认情况下通过轮询把消息均衡地分布到主题的所有分区上。
- 在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上
- 生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。

## Consumer

消息消费者，从 Broker 读取消息的客户端

- 消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。
- 消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或重启，它的读取状态不会丢失。
- 消费者是消费组的一部分。群组保证每个分区只能被一个消费者使用。
- 如果一个消费者失效，消费组里的其他消费者可以接管失效消费者的工作，再平衡，分区重新分配。

## Partition

- 主题可以被分为若干个分区，一个分区就是一个提交日志。
- 消息以追加的方式写入分区，然后以先入先出的顺序读取。
- 无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。
- Kafka 通过分区来实现数据冗余和伸缩性。
- 在需要严格保证消息的消费顺序的场景下，需要将 partition 数目设为 1。

## Replicas

在 broker 上，每个 broker 可以保存成百上千个属于不同主题和分区的副本。

副本有以下两种类型：

- 首领副本

  每个分区都有一个首领副本。为了保证一致性，所有生产者请求和消费者请求都会经过这个副本。

- 跟随者副本

  首领以外的副本都是跟随者副本。跟随者副本不处理来自客户端的请求，它们唯一的任务就是从首领那里复制消息，保持与首领一致的状态。如果首领发生崩溃，其中的一个跟随者会被提升为新首领。

## ConsumerGroup

消费者组，每个 Consumer 属于一个特定的 Consumer Group，一条消息可以被多个不同的 Consumer Group 消费，但是一个 Consumer Group 中只能有一个 Consumer 能够消费该消息

服务端(brokers)和客户端(producer、consumer)之间通信通过 TCP 协议来完成。
